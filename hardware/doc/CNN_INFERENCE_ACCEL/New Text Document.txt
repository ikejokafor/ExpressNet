“An EIE with processing power of 102 GOPS at only 600 mW is also 24,000x and 3,000x more energy efficient on respective CPUs and GPUs”

 Oreilly AI Conference 9/26/2016 – (EIE) -  https://www.dropbox.com/s/hs8826wjohlu7kr/Oreilly.pdf?dl=0

 Hardware for Deep Learning – 6/3/2016 - http://platformlab.stanford.edu/Seminar%20Talks/Hardware_for_DL_PlatformLab.pdf  ( slides 32 -33 )

 Deep Compression 5/4/2106 - https://pdfs.semanticscholar.org/642d/0f49b7826adcf986616f4af77e736229990f.pdf

 Deep Compression and EIE 4/7/2016 - http://on-demand.gputechconf.com/gtc/2016/presentation/s6561-song-han-deep-compression.pdf

 EIE -2/4/2016  https://arxiv.org/abs/1602.01528

 NIPS 2015 - https://media.nips.cc/Conferences/2015/tutorialslides/Dally-NIPS-Tutorial-2015.pdf

 


--------------------------------  OTHER IDEAs 

  

KnuEdge - http://www.da6nci.com/category/ai/neuromorphic-hardware/

Nvidia TensorRT - https://developer.nvidia.com/tensorrt   ( GPU )

GraphCore - https://www.graphcore.ai/technology  ( IPU )

Wave Computing - http://wavecomp.com/  ( DPU ) 

Movidius - http://www.movidius.com/technology  ( VPU )

DaDianNo - https://pdfs.semanticscholar.org/3946/249f4a4d00846e92ae3a92c98fbcc0761e71.pdf ( NFU ) 

Google - https://cloudplatform.googleblog.com/2016/05/Google-supercharges-machine-learning-tasks-with-custom-chip.html ( TPU )

Nervana Systems - https://www.nervanasys.com/technology/engine/  (ASIC)